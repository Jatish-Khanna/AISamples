{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOaSLnQO8rsJx6KiUUwN/u4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jatish-Khanna/AISamples/blob/main/Day3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5GVotnzqd9g9"
      },
      "outputs": [],
      "source": [
        "import streamlit as st\n",
        "import openai\n",
        "from datetime import datetime\n",
        "from advanced_context_manager import AdvancedContextManager, ConversationMemory, ContextStrategy\n",
        "\n",
        "# Page config\n",
        "st.set_page_config(page_title=\"Advanced AI Assistant\", layout=\"wide\")\n",
        "\n",
        "# Initialize\n",
        "if \"context_manager\" not in st.session_state:\n",
        "    st.session_state.context_manager = AdvancedContextManager(max_tokens=4000)\n",
        "\n",
        "if \"memory\" not in st.session_state:\n",
        "    st.session_state.memory = ConversationMemory()\n",
        "\n",
        "# Sidebar controls\n",
        "with st.sidebar:\n",
        "    st.header(\"Advanced Context Controls\")\n",
        "\n",
        "    # Context strategy selection\n",
        "    strategy_options = {\n",
        "        \"Sliding Window\": ContextStrategy.SLIDING_WINDOW,\n",
        "        \"Summarization\": ContextStrategy.SUMMARIZATION,\n",
        "        \"Importance-Based\": ContextStrategy.SEMANTIC_COMPRESSION,\n",
        "        \"Hierarchical\": ContextStrategy.HIERARCHICAL\n",
        "    }\n",
        "\n",
        "    selected_strategy = st.selectbox(\n",
        "        \"Context Strategy\",\n",
        "        options=list(strategy_options.keys()),\n",
        "        index=0\n",
        "    )\n",
        "\n",
        "    # Update strategy if changed\n",
        "    new_strategy = strategy_options[selected_strategy]\n",
        "    if st.session_state.memory.context_strategy != new_strategy:\n",
        "        st.session_state.memory.context_strategy = new_strategy\n",
        "        st.session_state.context_manager.strategy = new_strategy\n",
        "\n",
        "    # Token limit adjustment\n",
        "    max_tokens = st.slider(\n",
        "        \"Max Context Tokens\",\n",
        "        min_value=1000,\n",
        "        max_value=8000,\n",
        "        value=4000,\n",
        "        step=500\n",
        "    )\n",
        "    st.session_state.context_manager.max_tokens = max_tokens\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # Context statistics\n",
        "    stats = st.session_state.context_manager.get_context_stats(st.session_state.memory)\n",
        "\n",
        "    st.subheader(\"Context Analytics\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "    with col1:\n",
        "        st.metric(\"Messages\", stats.get(\"total_messages\", 0))\n",
        "        st.metric(\"Token Usage\", f\"{stats.get('token_utilization', 0):.1%}\")\n",
        "\n",
        "    with col2:\n",
        "        st.metric(\"Total Tokens\", stats.get(\"total_tokens\", 0))\n",
        "        st.metric(\"Avg Importance\", f\"{stats.get('avg_importance', 0):.1f}\")\n",
        "\n",
        "    # Message type breakdown\n",
        "    if stats.get(\"message_types\"):\n",
        "        st.subheader(\"Message Types\")\n",
        "        for msg_type, count in stats[\"message_types\"].items():\n",
        "            st.text(f\"{msg_type}: {count}\")\n",
        "\n",
        "    # Session info\n",
        "    st.subheader(\"Session Info\")\n",
        "    st.text(f\"Strategy: {stats.get('strategy', 'unknown')}\")\n",
        "    st.text(f\"Duration: {stats.get('session_duration', 0):.1f} min\")\n",
        "    st.text(f\"Summaries: {stats.get('summaries_created', 0)}\")\n",
        "\n",
        "    st.divider()\n",
        "\n",
        "    # Advanced controls\n",
        "    st.subheader(\"Advanced Controls\")\n",
        "\n",
        "    if st.button(\"Clear Conversation\"):\n",
        "        st.session_state.memory = ConversationMemory(\n",
        "            context_strategy=new_strategy\n",
        "        )\n",
        "        st.rerun()\n",
        "\n",
        "    if st.button(\"Force Summarization\"):\n",
        "        # Temporarily lower threshold to force summarization\n",
        "        original_threshold = st.session_state.context_manager.summary_threshold\n",
        "        st.session_state.context_manager.summary_threshold = 0\n",
        "        st.session_state.memory = st.session_state.context_manager._summarization_strategy(\n",
        "            st.session_state.memory\n",
        "        )\n",
        "        st.session_state.context_manager.summary_threshold = original_threshold\n",
        "        st.rerun()\n",
        "\n",
        "    if st.button(\"Export Conversation\"):\n",
        "        export_data = st.session_state.context_manager.export_conversation(\n",
        "            st.session_state.memory\n",
        "        )\n",
        "        st.download_button(\n",
        "            \"Download JSON\",\n",
        "            data=export_data,\n",
        "            file_name=f\"conversation_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\",\n",
        "            mime=\"application/json\"\n",
        "        )\n",
        "\n",
        "# Main interface\n",
        "st.title(f\"🧠 Advanced AI Assistant\")\n",
        "st.caption(f\"Context Strategy: {selected_strategy} | Token Limit: {max_tokens:,}\")\n",
        "\n",
        "# Display token usage bar\n",
        "if stats.get(\"total_tokens\", 0) > 0:\n",
        "    usage_pct = stats[\"token_utilization\"]\n",
        "    st.progress(usage_pct)\n",
        "\n",
        "    if usage_pct > 0.8:\n",
        "        st.warning(\"Context approaching token limit - older messages may be compressed\")\n",
        "    elif usage_pct > 0.9:\n",
        "        st.error(\"Context nearly full - active memory management in effect\")\n",
        "\n",
        "# Chat interface with enhanced display\n",
        "chat_container = st.container()\n",
        "\n",
        "with chat_container:\n",
        "    for i, (message, metadata) in enumerate(zip(st.session_state.memory.messages, st.session_state.memory.metadata)):\n",
        "        role = message.get(\"role\", \"\")\n",
        "        content = message.get(\"content\", \"\")\n",
        "\n",
        "        # Enhanced message display with metadata\n",
        "        if role == \"system\":\n",
        "            if \"[SUMMARY]\" in content or \"[ARCHIVED]\" in content:\n",
        "                with st.expander(f\"📋 {metadata.message_type.title()} (Importance: {metadata.importance_score:.1f})\"):\n",
        "                    st.info(content)\n",
        "            else:\n",
        "                st.info(content)\n",
        "        elif role == \"user\":\n",
        "            with st.chat_message(\"user\"):\n",
        "                st.write(content)\n",
        "                # Show metadata in debug mode\n",
        "                if st.checkbox(f\"Show metadata {i}\", key=f\"meta_{i}\"):\n",
        "                    st.json({\n",
        "                        \"timestamp\": metadata.timestamp.strftime(\"%H:%M:%S\"),\n",
        "                        \"tokens\": metadata.token_count,\n",
        "                        \"importance\": metadata.importance_score,\n",
        "                        \"type\": metadata.message_type\n",
        "                    })\n",
        "        elif role == \"assistant\":\n",
        "            with st.chat_message(\"assistant\"):\n",
        "                st.write(content)\n",
        "\n",
        "# Input area\n",
        "user_input = st.chat_input(\"Ask me anything...\")\n",
        "\n",
        "if user_input:\n",
        "    # Add user message\n",
        "    user_message = {\"role\": \"user\", \"content\": user_input}\n",
        "    st.session_state.memory = st.session_state.context_manager.add_message(\n",
        "        st.session_state.memory,\n",
        "        user_message\n",
        "    )\n",
        "\n",
        "    # Display user message\n",
        "    with st.chat_message(\"user\"):\n",
        "        st.write(user_input)\n",
        "\n",
        "    # Generate response\n",
        "    with st.chat_message(\"assistant\"):\n",
        "        try:\n",
        "            # Prepare messages for API\n",
        "            api_messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}]\n",
        "\n",
        "            # Add conversation messages\n",
        "            for msg in st.session_state.memory.messages:\n",
        "                if msg.get(\"role\") in [\"user\", \"assistant\"]:\n",
        "                    api_messages.append(msg)\n",
        "\n",
        "            # Call OpenAI API\n",
        "            with st.spinner(\"Thinking...\"):\n",
        "                response = openai.chat.completions.create(\n",
        "                    model=\"gpt-3.5-turbo\",\n",
        "                    messages=api_messages[-10:],  # Last 10 messages to avoid context overflow\n",
        "                    temperature=0.7,\n",
        "                    max_tokens=1000\n",
        "                )\n",
        "\n",
        "                assistant_response = response.choices[0].message.content\n",
        "                st.write(assistant_response)\n",
        "\n",
        "                # Add assistant response to memory\n",
        "                assistant_message = {\"role\": \"assistant\", \"content\": assistant_response}\n",
        "                st.session_state.memory = st.session_state.context_manager.add_message(\n",
        "                    st.session_state.memory,\n",
        "                    assistant_message\n",
        "                )\n",
        "\n",
        "        except Exception as e:\n",
        "            st.error(f\"Error: {e}\")\n",
        "\n",
        "# Context visualization\n",
        "st.divider()\n",
        "with st.expander(\"🔍 Context Visualization\"):\n",
        "    if st.session_state.memory.messages:\n",
        "        st.subheader(\"Message Importance Timeline\")\n",
        "\n",
        "        # Create a simple visualization of message importance over time\n",
        "        importance_data = []\n",
        "        for i, (msg, meta) in enumerate(zip(st.session_state.memory.messages, st.session_state.memory.metadata)):\n",
        "            importance_data.append({\n",
        "                \"Message\": i + 1,\n",
        "                \"Importance\": meta.importance_score,\n",
        "                \"Tokens\": meta.token_count,\n",
        "                \"Role\": msg.get(\"role\", \"unknown\"),\n",
        "                \"Type\": meta.message_type\n",
        "            })\n",
        "\n",
        "        st.dataframe(importance_data, use_container_width=True)\n",
        "\n",
        "        # Show memory management events\n",
        "        st.subheader(\"Memory Management Log\")\n",
        "        if st.session_state.memory.summaries:\n",
        "            st.write(f\"📝 {len(st.session_state.memory.summaries)} summarization events\")\n",
        "            for i, summary in enumerate(st.session_state.memory.summaries):\n",
        "                st.text(f\"Summary {i+1}: {summary['content'][:100]}...\")\n",
        "        else:\n",
        "            st.write(\"No memory management events yet\")\n",
        "\n",
        "# Testing panel\n",
        "st.divider()\n",
        "with st.expander(\"🧪 Strategy Testing\"):\n",
        "    st.subheader(\"Test Context Strategies\")\n",
        "\n",
        "    col1, col2 = st.columns(2)\n",
        "\n",
        "    with col1:\n",
        "        if st.button(\"Add Spam Messages\"):\n",
        "            spam_messages = [\n",
        "                {\"role\": \"user\", \"content\": f\"Test message {i}\"},\n",
        "                {\"role\": \"assistant\", \"content\": f\"Response {i}\"}\n",
        "                for i in range(5)\n",
        "            ]\n",
        "\n",
        "            for msg in spam_messages:\n",
        "                st.session_state.memory = st.session_state.context_manager.add_message(\n",
        "                    st.session_state.memory, msg\n",
        "                )\n",
        "            st.rerun()\n",
        "\n",
        "    with col2:\n",
        "        if st.button(\"Add Important Message\"):\n",
        "            important_msg = {\n",
        "                \"role\": \"user\",\n",
        "                \"content\": \"This is extremely important information that I need to remember for later: The secret code is 12345.\"\n",
        "            }\n",
        "            st.session_state.memory = st.session_state.context_manager.add_message(\n",
        "                st.session_state.memory, important_msg\n",
        "            )\n",
        "            st.rerun()\n",
        "\n",
        "# Footer\n",
        "st.divider()\n",
        "st.caption(\"Day 3: Advanced Context Management - Understanding how AI systems handle memory constraints\")"
      ]
    }
  ]
}